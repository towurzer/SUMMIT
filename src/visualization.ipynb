{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tokenizers\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from config import Config\n",
    "from model import Model\n",
    "from train import DataSetLoader, Training\n",
    "from dataset import TranslationDataset\n",
    "from config import Config\n",
    "from transformer import Transformer\n",
    "from transformer import TransformerBuilder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the ipynb notebook launches from project root folder to be able to reuse existing model/tokenizers but still having access to modules\n",
    "import os\n",
    "\n",
    "print(f\"Starting directory: {os.getcwd()}\")\n",
    "if os.path.basename(os.getcwd()) == \"src\":\n",
    "\tos.chdir('../')\n",
    "\tprint(f\"Moved working directory to: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the device \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "torch.cuda.empty_cache() #Frees memory no longer in use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = Path('config.json')\n",
    "config = Config(config_file_path)\n",
    "model = Model(config)\n",
    "model.load_latest_model() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, validation_ds, test_ds, tokenizer_source, tokenizer_target = DataSetLoader.get_dataset(model)\n",
    "validation_dataloader = DataLoader(validation_ds, batch_size=1, shuffle=True)\n",
    "val_iter = iter(validation_dataloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the next batch from the validation set\n",
    "max_tokens = config.train_config[\"max_sentence_tokens\"]\n",
    "output = 0\n",
    "\n",
    "def load_batch():\n",
    "\tbatch = next(val_iter) # Loads the next iteration of the validation\n",
    "\t\n",
    "\t#Gets the inputs via the keys from the dictionary that the dataset we downloaded provides\n",
    "\tencoder_input = batch[\"to_encoder\"].to(device)  \n",
    "\tdecoder_input = batch[\"to_decoder\"].to(device)  \n",
    "\tencoder_mask = batch[\"mask_encoder\"].to(device) \n",
    "\tdecoder_mask = batch[\"mask_decoder\"].to(device) \n",
    "\n",
    "\tencoder_input_tokens = [tokenizer_source.id_to_token(idx) for idx in encoder_input.squeeze(0)] \n",
    "\tdecoder_input_tokens = [tokenizer_target.id_to_token(idx) for idx in decoder_input.squeeze(0)]\n",
    "\t#Has to be squeezed since the DataLoader always provides a Batch dimension, even if it is 1 as in this case\n",
    "\n",
    "\tdecode_sentence(model.model, encoder_input, encoder_mask, tokenizer_source, tokenizer_target, max_tokens, device)\n",
    "\t#Is being called to load the attention scores for the new sentence\n",
    "\n",
    "\treturn batch, encoder_input_tokens, decoder_input_tokens\n",
    "\n",
    "\n",
    "def decode_sentence(model, to_encoder, mask_encoder, tokenizer_source, tokenizer_target, config, device):\n",
    "\ts_token = tokenizer_target.token_to_id(\"<S>\")\n",
    "\te_token = tokenizer_target.token_to_id(\"<E>\")\n",
    "\n",
    "\tencoded = model.encode(to_encoder, mask_encoder) \n",
    "\tto_decoder = torch.empty(1,1).fill_(s_token).type_as(to_encoder).to(device)\n",
    "\n",
    "\tfor iteration in range(0, max_tokens): # iterates until it reaches the limit for the sequence length\n",
    "\n",
    "\t\tmask_decoder = TranslationDataset.triangular_mask(to_decoder.size(1)).type_as(mask_encoder).to(device) \n",
    "\t\toutput = model.decode(encoded, mask_encoder, to_decoder, mask_decoder) #Returns a tensor of logits\n",
    "\n",
    "\t\tp = model.project(output[:, -1])\t\t\t\t\t\t#Model projects the decoder output into a logits vector over the vocabulary\n",
    "\t\tnot_needed_values, most_likely = torch.max(p, dim=1)\t#Selects the most likely next tokens, values are not needed here, only the token itself\n",
    "\t\tif most_likely == e_token: break \n",
    "\n",
    "\t\tto_decoder = torch.cat([ to_decoder,torch.empty(1,1).type_as(to_encoder).fill_(most_likely.item()).to(device)], dim=1)  \n",
    "\t\t# Concats the new token to to_decoder, the next most_likely token will then be different and added again\n",
    "\n",
    "\t\t#Output = 3D Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if it really works\n",
    "\n",
    "batch = next(val_iter) # Loads the next iteration of the validation\n",
    "encoder_input = batch[\"to_encoder\"].to(device)  # Gets the encoder-input of the item in the batch\n",
    "decoder_input = batch[\"to_decoder\"].to(device)\n",
    "\n",
    "encoder_input_tokens = [tokenizer_source.id_to_token(index) for index in encoder_input.cpu().squeeze(0)] #Turns ID's into tokens\n",
    "decoder_input_tokens = [tokenizer_target.id_to_token(index) for index in decoder_input.cpu().squeeze(0)]\n",
    "\n",
    "print(encoder_input_tokens)\n",
    "print(decoder_input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_dataframe(attention_matrix, max_row, max_col, row_tokens, col_tokens): # Converts attention matrix into Pandas Dataframe\n",
    "\tdata = [] \n",
    "\tfor row in range(attention_matrix.shape[0]): \n",
    "\t\tfor col in range(attention_matrix.shape[1]): \n",
    "\n",
    "\t\t\tif row < max_row and col < max_col:\n",
    "\t\t\t\tattention_value = float(attention_matrix[row, col])\n",
    "\n",
    "\t\t\t\trow_token = row_tokens[row] if row < len(row_tokens) else \"<blank>\"\n",
    "\t\t\t\tcol_token = col_tokens[col] if col < len(col_tokens) else \"<blank>\"\n",
    "\n",
    "\t\t\t\trow_label = f\"{row:03d} {row_token}\"\n",
    "\t\t\t\tcol_label = f\"{col:03d} {col_token}\"\n",
    "\t\t\t\t\n",
    "\t\t\t\tdata.append((row, col, attention_value, row_label, col_label)) # Adding tuples to the list\n",
    "\tdataframe = pd.DataFrame(data, columns=[\"row\", \"column\", \"value\", \"row_token\", \"col_token\"]) #Pass the data and the column names we assign\n",
    "\n",
    "\treturn dataframe\n",
    "\n",
    "\n",
    "def get_attention_map(attention_type: str, layer: int, head: int):\n",
    "\t#Based on input attention_type one of the attention types is chosen and returned.\n",
    "\tif attention_type == \"encoder\":\n",
    "\t\tattention = model.model.encoder.encoder_module_list._modules['0'].self_attention_layer.attention_scores\n",
    "\t\n",
    "\telif attention_type == \"decoder\":\n",
    "\t\tattention = model.model.decoder.decoder_module_list._modules['0'].self_attention_layer.attention_scores\n",
    "\n",
    "\telif attention_type == \"encoder-decoder\":\n",
    "\t\tattention = model.model.decoder.decoder_module_list._modules['0'].cross_attention_layer.attention_scores\n",
    "\t\n",
    "\t#attention = Size([1, 8, 50, 50]) is the batch size, heads, Query_len and Key_len\n",
    "\t#print(attention[0, head].shape) = Size([50, 50])\n",
    "\n",
    "\treturn attention[0, head].data #.data gives raw tensor data without gradient tracking from requires_grad (from backpropagation)\n",
    "\n",
    "def attention_map(attention_type, layer, head, row_tokens, col_tokens, max_sentence_len):\n",
    "\tdataframe = matrix_to_dataframe(get_attention_map(attention_type, layer, head), max_sentence_len, max_sentence_len, row_tokens, col_tokens) \n",
    "\n",
    "\treturn (\t\t\t\n",
    "\t\talt.Chart(dataframe).mark_rect().encode(\n",
    "\t\tx = \"col_token\", # X and Y have to match the name of the dataframe columns\n",
    "\t\ty = \"row_token\",\n",
    "\t\tcolor = alt.Color(\"value\", scale=alt.Scale(scheme=\"greens\")),\n",
    "\t\ttooltip=[\"row\", \"column\", \"value\", \"row_token\", \"col_token\"] #Which values are shown when hovering above the rectangles\n",
    "\t).properties(height=200, width=200, title = f\"Layer {layer}, Head {head}\") \n",
    "\t)\n",
    "\n",
    "def get_all_attention_maps(attention_type: str, layers: int, heads: int, row_tokens, col_tokens, max_sentence_len: int):\n",
    "\tcharts = [] \n",
    "\tfor layer in range(layers):\n",
    "\t\trowCharts = []\n",
    "\t\tfor head in range(heads):\n",
    "\t\t\trowCharts.append(attention_map(attention_type, layer, head, row_tokens, col_tokens, max_sentence_len))\n",
    "\t\tcharts.append(alt.hconcat(*rowCharts))\n",
    "\treturn alt.vconcat(*charts)\n",
    "\n",
    "\t# The * operator unpacks the list, so instead of [1, 2, 3] it gets (1, 2, 3) and it can work with that\n",
    "\t# Attention matrices of all heads and all layers that are given as the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, encoder_input_tokens, decoder_input_tokens = load_batch()\n",
    "print(batch.keys())  # Shows all available keys in the batch\n",
    "\n",
    "print(f'Source: {batch['text_source']}')\n",
    "print(f'Target: {batch['text_target']}')\n",
    "sentence_len = encoder_input_tokens.index(\"<P>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_heads = int(config.train_config[\"num_heads\"])\n",
    "number_layer = int(config.train_config[\"num_encoder_blocks\"])\n",
    "\n",
    "# Self-Attention-Encoder\n",
    "get_all_attention_maps(\"encoder\", number_layer, number_heads, encoder_input_tokens, encoder_input_tokens, min(20, sentence_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-Attention-Decoder\n",
    "get_all_attention_maps(\"decoder\", number_layer, number_heads, decoder_input_tokens, decoder_input_tokens, min(20, sentence_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Attention\n",
    "get_all_attention_maps(\"encoder-decoder\", number_layer, number_heads, encoder_input_tokens, decoder_input_tokens, min(20, sentence_len))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
